{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13_Project_2_TT.colab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMq86lur0aCKCtrpAwwP4rF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Revanthkrr-hub/Text-Generation/blob/master/13_Project_2_TT_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR_N40cgUTE6",
        "colab_type": "code",
        "outputId": "8efb1778-6527-4515-dc0f-e1110d90d2d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhSu7VwbHkiq",
        "colab_type": "code",
        "outputId": "0fc5f58e-cc01-4890-a01a-0e9d058b47aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 27kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 38.4MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 49.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.1.1\n",
            "    Uninstalling tensorboard-2.1.1:\n",
            "      Successfully uninstalled tensorboard-2.1.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc1\n",
            "    Uninstalling tensorflow-2.2.0rc1:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc1\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2ETKTqRU0XT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "491ebe06-332d-41b0-a9db-912459de30fa"
      },
      "source": [
        "\n",
        "# Standard Data Science Libraries\n",
        "import pickle\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "\n",
        "# Neural Net Preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# Neural Net Layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "# Neural Net Training\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from pickle import load"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnDr0b2tU4Y8",
        "colab_type": "code",
        "outputId": "5359af54-073a-4ddf-f596-179fbfad5182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import the data\n",
        "train= pd.read_csv('/content/train.csv')\n",
        "# Selecting Edgar Allen Poe as author style to emulate\n",
        "author= train[train['author'] == 'EAP'][\"text\"]\n",
        "print('Number of training sentences: ',author.shape[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences:  7900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3rQv0mGNZOx",
        "colab_type": "code",
        "outputId": "87258d22-0dbd-4434-f6d8-b3390c9613ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test= pd.read_csv('/content/test.csv')\n",
        "author_test = test[\"text\"]\n",
        "print('Number of training sentences: ',author_test.shape[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences:  8392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJx1UY3qVmeB",
        "colab_type": "code",
        "outputId": "c33bad18-5d0b-4de6-d98f-149be75f5612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "max_words = 50000 \n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(author.values)\n",
        "sequences = tokenizer.texts_to_sequences(author.values)\n",
        "print(sequences[:5])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[19, 2397, 80, 1001, 29, 31, 177, 2, 4073, 1, 1960, 2, 11, 3024, 15, 7, 110, 157, 41, 2146, 3, 481, 4, 1, 149, 2147, 7, 393, 74, 114, 101, 439, 2, 1, 162, 32, 913, 6453, 136, 1, 380], [6, 21, 142, 150, 10, 5, 551, 2148, 319, 28, 16, 15, 20, 8999, 128, 1, 3025, 2398, 30, 171, 2, 1797, 697, 20, 180, 2148, 6454, 12, 33, 188, 2, 1, 869, 243, 522, 1264], [1, 6455, 203, 14, 19, 149, 180, 6456, 6, 1, 1357, 2, 1358, 9000, 3, 83, 2149, 10, 355, 140, 794], [1, 4074, 491, 6, 9001, 28, 11, 158], [7, 287, 9, 36, 48, 22, 73, 4, 644, 9002, 114, 101, 346, 4, 271, 2, 9003, 3, 81, 2, 1, 3026, 2, 6457, 3, 282, 53, 34, 6458, 19, 339, 22, 43, 97, 608, 7, 450, 4, 36, 133, 1191, 88, 12, 133, 71, 914, 1, 759, 3027, 2, 9, 1445, 1359, 18, 760, 12, 4973, 6, 1, 421, 9004, 9005, 7, 214, 9, 36, 48, 22, 3449, 3028, 98, 124, 1192, 4, 1, 92, 9006, 6, 3450, 3, 7, 761, 870, 9, 36, 55, 111, 32]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44SDJ5TuVxM1",
        "colab_type": "code",
        "outputId": "5e611cb0-8adf-4bb6-e43c-86324414d40e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = [item for sublist in sequences for item in sublist]\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "print('Vocabulary size in this corpus: ', vocab_size)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size in this corpus:  15713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHtq_u4HV1pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training on 19 words to predict the 20th\n",
        "sen_len = 20\n",
        "pred_len = 1\n",
        "t_len = sen_len - pred_len\n",
        "seq = []\n",
        "\n",
        "for i in range(len(text)-sen_len):\n",
        "    seq.append(text[i:i+sen_len])\n",
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
        "\n",
        "trainX = []\n",
        "trainy = []\n",
        "for i in seq:\n",
        "    trainX.append(i[:t_len])\n",
        "    trainy.append(i[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOQdkLYnV5Ja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "980f7f6f-6b92-4809-d979-b75a8d2290c3"
      },
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size+1, 50, input_length=t_len),\n",
        "    LSTM(100, return_sequences=True),\n",
        "    LSTM(100),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "# model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sIjCYAfWZlk",
        "colab_type": "code",
        "outputId": "06ded396-b036-45b0-bc88-7bf7a9f11ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(np.asarray(trainX), pd.get_dummies(np.asarray(trainy)), batch_size=128, epochs=3)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/3\n",
            "201082/201082 [==============================] - 312s 2ms/sample - loss: 6.8170 - acc: 0.0840\n",
            "Epoch 2/3\n",
            "201082/201082 [==============================] - 296s 1ms/sample - loss: 6.3488 - acc: 0.1072\n",
            "Epoch 3/3\n",
            "201082/201082 [==============================] - 296s 1ms/sample - loss: 6.1196 - acc: 0.1226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f24dbb20240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "398DqcjQXEPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model_weights.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRNc4TwxXQYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae1f9849-8cd6-4c9d-d649-9a0e29f0c717"
      },
      "source": [
        "model_2 = Sequential([\n",
        "    Embedding(vocab_size+1, 50, input_length=t_len),\n",
        "    LSTM(100, return_sequences=True),\n",
        "    LSTM(100),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dropout(0.1),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "# model_2.compile(optimizer='adam',\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# history = model_2.fit(np.asarray(trainX),\n",
        "#          pd.get_dummies(np.asarray(trainy)),\n",
        "#          epochs = 300,\n",
        "#          batch_size = \n",
        "128,\n",
        "#          callbacks = callbacks_list,\n",
        "#          verbose = 1)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30xBWX4aXTjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_2.load_weights('/content/model_2_weights_colab.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fMSBGYbXb4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model_3 = Sequential([\n",
        "    Embedding(vocab_size+1, 50, input_length=t_len),\n",
        "    LSTM(150, return_sequences=True),\n",
        "    LSTM(150),\n",
        "    Dense(150, activation='relu'),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbcRRx04XgR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_3.load_weights('/content/model_3_weights_colab.hdf5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQh89Gw1Xukj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "404f7c0f-ff29-45ff-9bc0-050642fa6448"
      },
      "source": [
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Embedding,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from keras.losses import categorical_crossentropy\n",
        "from sklearn.metrics import accuracy_score,classification_report,f1_score\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# define model\n",
        "model_4 = Sequential([\n",
        "    Embedding(vocab_size+1, 50, input_length=t_len),\n",
        "    Conv1D(64,kernel_size=3,padding='same',activation='relu',strides=1),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dropout(0.2),\n",
        "    Dense(150, activation='relu'),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11M-DRQ1X5RH",
        "colab_type": "code",
        "outputId": "b82c66f8-1aab-42fe-a4f3-601530c912b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "model_4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_4.fit(np.asarray(trainX), pd.get_dummies(np.asarray(trainy)), batch_size=128, epochs=3)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "201082/201082 [==============================] - 205s 1ms/step - loss: 7.0042 - acc: 0.0735\n",
            "Epoch 2/3\n",
            "201082/201082 [==============================] - 205s 1ms/step - loss: 6.8000 - acc: 0.0745\n",
            "Epoch 3/3\n",
            "201082/201082 [==============================] - 204s 1ms/step - loss: 6.7058 - acc: 0.0856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f24f744d828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pys3TVG-UyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_4.save('model4_weights.hdf5')  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmtzWsaHdm5G",
        "colab_type": "code",
        "outputId": "c9d54dd0-a056-471c-eb62-bbfd328df55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "scores1 = model.evaluate(np.asarray(trainX), pd.get_dummies(np.asarray(trainy)), verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores1[1]*100))\n",
        "\n",
        "scores2 = model_2.evaluate(np.asarray(trainX), pd.get_dummies(np.asarray(trainy)), verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores2[1]*100))\n",
        "\n",
        "scores3 = model_3.evaluate(np.asarray(trainX), pd.get_dummies(np.asarray(trainy)), verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores3[1]*100))\n",
        "\n",
        "scores4 = model_4.evaluate(np.asarray(trainX), pd.get_dummies(np.asarray(trainy)), verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores4[1]*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 13.10%\n",
            "Accuracy: 38.48%\n",
            "Accuracy: 64.06%\n",
            "Accuracy: 10.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPk6W46SjZxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen(model,seq,max_len = 20):\n",
        "    t_sentence = tokenizer.texts_to_sequences([seq])\n",
        "    max_len = max_len+len(t_sentence[0])\n",
        "    while len(t_sentence[0]) < max_len:\n",
        "        padded_sentence = pad_sequences(t_sentence[-19:],maxlen=19)\n",
        "        op = model.predict(np.asarray(padded_sentence).reshape(1,-1))\n",
        "        t_sentence[0].append(op.argmax()+1)\n",
        "        \n",
        "    return \" \".join(map(lambda x : reverse_word_map[x],t_sentence[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8Y62GD5uiru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "407b355d-69a4-418f-f219-0d0603544fb8"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dist = train.groupby([\"author\"]).size()\n",
        "dist = dist / dist.sum()\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "sns.barplot(dist.keys(), dist.values);"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHgCAYAAABXfvCOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u5P9NAmjeoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result= [model,model_2,model_3,model_4]\n",
        "def test_models(test_string,sequence_length= 50, result = result):\n",
        "  '''Generates output given input test_string up to sequence_length'''\n",
        "  print('Input String: ', test_string)\n",
        "  for counter,model in enumerate(result):\n",
        "    print(\"Model \", counter+1, \":\")\n",
        "    print(gen(model,test_string,sequence_length))\n",
        "  pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUqdZ_ndiGbV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "172b6d88-4af9-48a0-d047-2af12dd54835"
      },
      "source": [
        "test_models('This process however afforded me', 10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input String:  This process however afforded me\n",
            "Model  1 :\n",
            "this process however afforded me to the most and and the most and and the\n",
            "Model  2 :\n",
            "this process however afforded me most well echoed one who had a very idea which\n",
            "Model  3 :\n",
            "this process however afforded me good difficulty whatever long vaulting are no more subject to\n",
            "Model  4 :\n",
            "this process however afforded me the the the the the the the the the the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar0xCHLCKcQg",
        "colab_type": "code",
        "outputId": "186621a0-207d-4967-950b-0b2bcd08bd85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "test_models(author_test.iloc[8390])\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input String:  Be this as it may, I now began to feel the inspiration of a burning hope, and at length nurtured in my secret thoughts a stern and desperate resolution that I would submit no longer to be enslaved.\n",
            "Model  1 :\n",
            "be this as it may i now began to feel the inspiration of a burning hope and at length nurtured in my secret thoughts a stern and desperate resolution that i would submit no longer to be the most and and the most and and the most and and the most and and the most and and the most and and the most and and the most and and the most and and the most and and the most and and the most and and the most\n",
            "Model  2 :\n",
            "be this as it may i now began to feel the inspiration of a burning hope and at length nurtured in my secret thoughts a stern and desperate resolution that i would submit no longer to be the most oil of water is not more more than the most idea of the most gazette who had been more a matter of great letters ' strenuous son out of the oil of bob a few words of music had been a very ascendancy far more than one and\n",
            "Model  3 :\n",
            "be this as it may i now began to feel the inspiration of a burning hope and at length nurtured in my secret thoughts a stern and desperate resolution that i would submit no longer to be that and his advice there was some angle of each or four feet four feet and loud or deadened into study about the immensely plane river i saw again so soundly and fragility a half susceptible of inquiries was of compassioning the sole argument of my button instituted but a\n",
            "Model  4 :\n",
            "be this as it may i now began to feel the inspiration of a burning hope and at length nurtured in my secret thoughts a stern and desperate resolution that i would submit no longer to be the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}